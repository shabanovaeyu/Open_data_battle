# Open_data_battle

Решение кейса на DS-хакатоне от банка "Открытие", 30-31 октября 2021 г.   
Ссылка на страницу мероприятия: [Open_data_battle](https://open-data-battle.geecko.com/issues)

## Постановка задачи

Банк разработал свою модель прогнозирования вероятности дефолта *(PD)*.  
Задача состояла в прогнозировании ошибки этой модели *ERROR*, вычисляемой как *abs(flg_90_12_add - PD)*, где  
*flg_90_12_add* - истинная метка класса ("0" - не дефолт, "1" - дефолт),  
*PD* - спрогнозированная моделью банка вероятность дефолта.

Метрика оценки качества - *Mean Absolute Error (MAE)*.  

## Проблема
В данных наблюдается сильная разбалансировка классов - на 20 случаев мажоритарного класса  
приходится один миноритарный. Поэтому **модель банка** практически **не распознает класс 1**.

## Идея

**"Подружить" прогнозы** модели регрессии и классификации:  

* спрогнозировать ошибки *ERROR* напрямую с помощью регрессионной модели  
* спрогнозировать класс *flg_90_12_add* в части меток "1" *аккуратнее модели банка* 
* на примерах с уверенным предсказаением класса "1" cкорректировать *ERROR*

## Формальные процедуры

Предобработка данных:  
- удаление столбцов с количеством пропусков > 50%  
- удаление строк с количеством пропусков > 50%  
- замена оставшихся пропусков средними по полю значениями  
- стандартизация набора признаков *MinMaxScaler*-ом  

Задача классификации:  
- модель *RandomForestClassifier*  
- добавление нелинейных признаков  
- балансировка классов методом *SMOTE*  

Задача регрессии:  
- модель *RandomForestRegressor*  
- обучение только на примерах класса "0"  

## Что не улучшило качество метрики
- удаление столбцов и строк с наличием хотя бы одного пропуска  
- прогнозирование ошибки по *k = 2, 3, 4, 5* - ближайшим соседям  
- обучение *RandomForestRegressor* на примерах обоих классов  
- логарифмирование целевой переменной *ERROR*  

## На что не хватило времени
- андерсамплинг и другие методы оверсамплинга, кроме *SMOTE*  
- поиск модели с похожим на модель банка распределением вероятностей *PD*  
- более тщательный отбор признаков для модели  

## Итоговое качество прогноза
*MAE* = 0.0574  

P.S. это могло быть 4 место в скоре, если бы я отправила это решение :confused:
